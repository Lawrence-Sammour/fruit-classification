{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTaVZ4M9Y3bn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import tarfile\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.transforms as tt\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScBldc5KZe9g",
        "outputId": "e49e805c-e12b-4338-a248-32c8ccfaf8d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/Kaggle\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Kaggle\"\n",
        "%cd /content/gdrive/MyDrive/Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb1r50XEeAEz"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/gdrive/MyDrive/datasets2/fruits-360_dataset/fruits-360/'\n",
        "\n",
        "train_dataset = ImageFolder(data_dir + \"Training\", transform=ToTensor())\n",
        "\n",
        "test_dataset = ImageFolder(data_dir + \"Test\", transform=ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwV_X-_Kei_g"
      },
      "outputs": [],
      "source": [
        "dataset_size = len(train_dataset)\n",
        "test_dataset_size = len(test_dataset)\n",
        "print(train_dataset)\n",
        "print(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxkOs8bPaPbH"
      },
      "outputs": [],
      "source": [
        "# Accesssing the classes\n",
        "data_dir = '/content/gdrive/MyDrive/datasets/'\n",
        "\n",
        "# print(os.listdir(data_dir))\n",
        "classes = os.listdir(data_dir + \"Training\")\n",
        "print(f'Total Number of Classes {len(classes)}')\n",
        "print(f'Classes Names: {classes}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RA1wqDXjgBHw"
      },
      "outputs": [],
      "source": [
        "#before resizing function\n",
        "img, label = train_dataset[0]\n",
        "img_shape = img.shape\n",
        "img_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_vO3vHWiTq2"
      },
      "outputs": [],
      "source": [
        "img, label = train_dataset[0]\n",
        "plt.imshow(img.permute((1, 2, 0)))\n",
        "print('Label (numeric):', label)\n",
        "print('Label (textual):', classes[label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekZzWUi3h03Z"
      },
      "outputs": [],
      "source": [
        "def get_mean_and_std(dataloader):\n",
        "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
        "    for data, _ in dataloader:\n",
        "        # Mean over batch, height and width, but not over the channels\n",
        "        channels_sum += torch.mean(data, dim=[0,2,3])\n",
        "        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
        "        num_batches += 1\n",
        "    \n",
        "    mean = channels_sum / num_batches\n",
        "\n",
        "    # std = sqrt(E[X^2] - (E[X])^2)\n",
        "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
        "\n",
        "    return mean, std\n",
        "# get_mean_and_std(train_dataloader)\n",
        "# get_mean_and_std(test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60IDy9VOlItN"
      },
      "outputs": [],
      "source": [
        "# Data transforms (data augmentation)\n",
        "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "train_tfms = tt.Compose([\n",
        "                         tt.RandomCrop(100, padding=4, padding_mode='reflect'), \n",
        "                         tt.Resize((100,100)),\n",
        "                         tt.RandomHorizontalFlip(), \n",
        "                         # tt.RandomRotate\n",
        "                         # tt.RandomResizedCrop(256, scale=(0.5,0.9), ratio=(1, 1)), \n",
        "                         # tt.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "                         tt.ToTensor(),\n",
        "                         tt.Normalize((0.4914, 0.4822, 0.4465),(0.2023, 0.1994, 0.2010))\n",
        "                         ])\n",
        "valid_tfms = tt.Compose([tt.ToTensor(), \n",
        "                        tt.Resize((100,100), tt.Normalize((0.4914, 0.4822, 0.4465),(0.2023, 0.1994, 0.2010))\n",
        ")])\n",
        "#tt.Normalize((0.4914, 0.4822, 0.4465),(0.2023, 0.1994, 0.2010))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6OTBtpFnjgj"
      },
      "outputs": [],
      "source": [
        "dataset = ImageFolder(data_dir + \"/Training\", transform=train_tfms)\n",
        "\n",
        "Testing = ImageFolder(data_dir + \"/Test\", transform=valid_tfms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwjNiWvOfXKf"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(43)\n",
        "val_size = round(len(dataset) * 0.2)\n",
        "train_size = round(len(dataset) - val_size)\n",
        "\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "len(train_ds), len(val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfqQ2lyWpcef"
      },
      "outputs": [],
      "source": [
        "batch_size=400\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKtlNEtwnQHH"
      },
      "outputs": [],
      "source": [
        "def denormalize(images, means, stds):\n",
        "    means = torch.tensor(means).reshape(1, 3, 1, 1)\n",
        "    stds = torch.tensor(stds).reshape(1, 3, 1, 1)\n",
        "    return images * stds + means\n",
        "\n",
        "\n",
        "def show_batch(dl):\n",
        "    for images, labels in dl:\n",
        "        fig, ax = plt.subplots(figsize=(12, 12))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        denorm_images = denormalize(images, (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
        "        break\n",
        "        # Data transforms (normalization & data augmentation)\n",
        "    #     def show_batch(dl):\n",
        "    # for images, labels in dl:\n",
        "    #     #print(images.shape)\n",
        "    #     fig, ax = plt.subplots(figsize=(12, 12))\n",
        "    #     ax.set_xticks([]); ax.set_yticks([])\n",
        "    #     denorm_images = denormalize(images, *stats)\n",
        "    #     ax.imshow(make_grid(denorm_images[:64], nrow=8).permute(1, 2, 0).clamp(0,1))\n",
        "    #     break\n",
        "\n",
        "show_batch(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyW5MHmXtkmd"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXafPB9Btysj"
      },
      "outputs": [],
      "source": [
        "device = get_default_device()\n",
        "device\n",
        "\n",
        "train_dl = DeviceDataLoader(train_loader, device)\n",
        "valid_dl = DeviceDataLoader(val_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfvZFL5InUK6"
      },
      "outputs": [],
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxpb_rOdnUIA"
      },
      "outputs": [],
      "source": [
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZbuYc4S8orj"
      },
      "outputs": [],
      "source": [
        "# # Only run this cell if u want to reset the model parameters\n",
        "# def weight_reset(m):\n",
        "#     if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "#         m.reset_parameters()\n",
        "\n",
        "# model.apply(weight_reset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ig2AeeZynUEf"
      },
      "outputs": [],
      "source": [
        "class Fruit360CnnModel(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            \n",
        "            nn.Conv2d(3, 16, kernel_size=2, padding=1), \n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # 16 X 50 X 50\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=2, stride=1, padding=1), \n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # 32 X 25 X 25\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=2, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(5, 5), # 64 X 5 X 5\n",
        "\n",
        "            nn.Flatten(), \n",
        "            nn.Dropout(0.3),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64*5*5, 24))\n",
        "        \n",
        "    def forward(self, xb):\n",
        "      return self.network(xb)\n",
        "\n",
        "model = Fruit360CnnModel()\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "177kr2ClQn-H"
      },
      "outputs": [],
      "source": [
        "FILE = \"model.pth\"\n",
        "model = torch.load(FILE)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yR7mnQonUB3"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
        "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "    \n",
        "    # Set up cutom optimizer with weight decay\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
        "    # Set up one-cycle learning rate scheduler\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
        "                                                steps_per_epoch=len(train_loader))\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            \n",
        "            # Gradient clipping\n",
        "            if grad_clip: \n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "            \n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Record & update learning rate\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step()\n",
        "        \n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EI8W-nLIw0OI"
      },
      "outputs": [],
      "source": [
        "# Moving the model to GPU\n",
        "model = to_device(model, device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4aZQq8pw0L0"
      },
      "outputs": [],
      "source": [
        "os.environ['WANDB_CONSOLE'] = 'off'\n",
        "\n",
        "history = [evaluate(model, valid_dl)]\n",
        "history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wle8U2O3w0Jf"
      },
      "outputs": [],
      "source": [
        "epochs = 4\n",
        "max_lr = 0.01\n",
        "grad_clip = 0.1\n",
        "weight_decay = 1e-4\n",
        "opt_func = torch.optim.Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpjsWShxOUGu"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "os.environ['WANDB_CONSOLE'] = 'off'\n",
        "\n",
        "history += fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, \n",
        "                             grad_clip=grad_clip, \n",
        "                             weight_decay=weight_decay, \n",
        "                             opt_func=opt_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6oXhCOrU1fg"
      },
      "outputs": [],
      "source": [
        "FILE = \"model.pth\"\n",
        "torch.save(model, FILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eL6Rwjt7OVSK"
      },
      "outputs": [],
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');\n",
        "\n",
        "plot_accuracies(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfYnLD9kOnQU"
      },
      "outputs": [],
      "source": [
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');\n",
        "\n",
        "plot_losses(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bh53c1BIpDc8"
      },
      "outputs": [],
      "source": [
        "def plot_lrs(history):\n",
        "    lrs = np.concatenate([x.get('lrs', []) for x in history])\n",
        "    plt.plot(lrs)\n",
        "    plt.xlabel('Batch no.')\n",
        "    plt.ylabel('Learning rate')\n",
        "    plt.title('Learning Rate vs. Batch no.');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrwHAyczpDZg"
      },
      "outputs": [],
      "source": [
        "plot_lrs(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOvuy6YsIxtq"
      },
      "outputs": [],
      "source": [
        "FILE = \"model.pth\"\n",
        "model = torch.load(FILE)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOElNkqiidge"
      },
      "outputs": [],
      "source": [
        "def f1_loss(y_true:torch.Tensor, y_pred:torch.Tensor, is_training=False) -> torch.Tensor:\n",
        "  \n",
        "    assert y_true.ndim == 1\n",
        "    assert y_pred.ndim == 1 or y_pred.ndim == 2\n",
        "    \n",
        "    if y_pred.ndim == 2:\n",
        "        y_pred = y_pred.argmax(dim=1)\n",
        "        \n",
        "    \n",
        "    tp = (y_true * y_pred).sum().to(torch.float32)\n",
        "    tn = ((1 - y_true) * (1 - y_pred)).sum().to(torch.float32)\n",
        "    fp = ((1 - y_true) * y_pred).sum().to(torch.float32)\n",
        "    fn = (y_true * (1 - y_pred)).sum().to(torch.float32)\n",
        "    \n",
        "    epsilon = 1e-7\n",
        "    \n",
        "    precision = tp / (tp + fp + epsilon)\n",
        "    recall = tp / (tp + fn + epsilon)\n",
        "    \n",
        "    f1 = 2* (precision*recall) / (precision + recall + epsilon)\n",
        "    f1.requires_grad = is_training\n",
        "   \n",
        "    return f1\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DO_BDTF01xfo"
      },
      "outputs": [],
      "source": [
        "test_tfms = tt.Compose([tt.Resize((100, 100)), \n",
        "                        tt.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac2qpd1g1xbt"
      },
      "outputs": [],
      "source": [
        "test_dataset = ImageFolder(data_dir + \"/Test\", transform=test_tfms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EWLz9bb1xZB"
      },
      "outputs": [],
      "source": [
        "test_loader = DeviceDataLoader(DataLoader(test_dataset, batch_size), device)\n",
        "result = evaluate(model, test_loader)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ucravey1xWk"
      },
      "outputs": [],
      "source": [
        "def predict_image(img, model):\n",
        "    # Convert to a batch of 1\n",
        "    xb = to_device(img.unsqueeze(0), device)\n",
        "    # Get predictions from model\n",
        "    yb = model(xb)\n",
        "    # Pick index with highest probability\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "    # Retrieve the class label\n",
        "    return dataset.classes[preds[0].item()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iabwnJnc1xT6"
      },
      "outputs": [],
      "source": [
        "for element in test_dataset:\n",
        "  i=0\n",
        "img, label = test_dataset[i]\n",
        "print(label)\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], 'Predicted:', predict_image(img, model))\n",
        "i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRExRnlg0URb"
      },
      "outputs": [],
      "source": [
        "img, label = test_dataset[512]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRbt7YMS2kBo"
      },
      "outputs": [],
      "source": [
        "img, label = test_dataset[3015]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AadT22EUVRd"
      },
      "outputs": [],
      "source": [
        "img, label = test_dataset[1]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], 'Predicted:', predict_image(img, model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B_8XKReUbrb"
      },
      "outputs": [],
      "source": [
        "img, label = test_dataset[120]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], 'Predicted:', predict_image(img, model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wpxDNSzUfKg"
      },
      "outputs": [],
      "source": [
        "img, label = test_dataset[400]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], 'Predicted:', predict_image(img, model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGjdKpTWUjA6"
      },
      "outputs": [],
      "source": [
        "img, label = test_dataset[600]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], 'Predicted:', predict_image(img, model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DaIVXLqUnBt"
      },
      "outputs": [],
      "source": [
        "img, label = test_dataset[2010]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], 'Predicted:', predict_image(img, model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nwi7PwQpXETp"
      },
      "outputs": [],
      "source": [
        "img, label = test_dataset[3000]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], 'Predicted:', predict_image(img, model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJyo9ghFXX-K"
      },
      "outputs": [],
      "source": [
        "\n",
        "img, label = test_dataset[0]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], 'Predicted:', predict_image(img, model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v83_1KBX7Ncx"
      },
      "outputs": [],
      "source": [
        "#print(metrics.classification_report(arrLabel,arrPred, 1))\n",
        "print('Ground Truth: {}'.format(img))\n",
        "print('Predicted Truth: {}'.format(label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqmwJVbuUkHA"
      },
      "outputs": [],
      "source": [
        "from torch.functional import Tensor\n",
        "from sklearn.metrics import f1_score \n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "x_data = torch.tensor(img)\n",
        "x_label = torch.tensor(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTXSnESMEALq"
      },
      "outputs": [],
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {: 0 for classes in classes}\n",
        "total_pred = {classes: 0 for classes in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in dataloaders['Test']:\n",
        "        images, labels = data\n",
        "        outputs = model_ft(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classes, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classes]\n",
        "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classes,\n",
        "                                                   accuracy))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "final_version.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
